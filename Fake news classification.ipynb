{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1iVMEShjlzcp_qCRxyzNuO40Umg2K9xj3","authorship_tag":"ABX9TyMZ2r6Ukob+m5r6qN2CkWeS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SNjymYcNb0nO","executionInfo":{"status":"ok","timestamp":1749385063172,"user_tz":-330,"elapsed":10624,"user":{"displayName":"AISHVARY VARYANI (2K22/EC/23)","userId":"05607320676924698127"}},"outputId":"c37d0a09-295d-4435-fa6f-d68b9a06f246"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8668561434193266\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.85      0.55      0.67      1105\n","           1       0.87      0.97      0.92      3469\n","\n","    accuracy                           0.87      4574\n","   macro avg       0.86      0.76      0.79      4574\n","weighted avg       0.86      0.87      0.86      4574\n","\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import FeatureUnion, Pipeline\n","from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Load dataset\n","df = pd.read_csv('/content/drive/MyDrive/FakeNewsNet.csv/FakeNewsNet.csv')\n","\n","# Drop rows with missing values in relevant columns\n","df = df[['tweet_num', 'source_domain', 'title', 'real']].dropna()\n","\n","# Define feature extraction functions\n","def get_title(X):\n","    return X['title']\n","\n","def get_domain(X):\n","    return X[['source_domain']]\n","\n","def get_tweet_num(X):\n","    return X[['tweet_num']]\n","\n","# Preprocessing and feature engineering\n","preprocessor = ColumnTransformer([\n","    ('title_tfidf', TfidfVectorizer(max_features=1000), 'title'),\n","    ('domain_ohe', OneHotEncoder(handle_unknown='ignore'), ['source_domain']), # Changed 'source_domain' to ['source_domain']\n","    ('tweet_num', FunctionTransformer(lambda x: x[['tweet_num']]), ['tweet_num'])\n","])\n","\n","# Create pipeline\n","pipeline = Pipeline([\n","    ('preprocessing', preprocessor),\n","    ('classifier', LogisticRegression(max_iter=2000))\n","])\n","\n","# Define features and target\n","X = df[['tweet_num', 'source_domain', 'title']]\n","y = df['real'].astype(int)  # Assuming 1 for real, 0 for fake\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train model\n","pipeline.fit(X_train, y_train)\n","\n","# Evaluate model\n","y_pred = pipeline.predict(X_test)\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"]},{"cell_type":"code","source":[],"metadata":{"id":"2ZAsktiXeX_U"},"execution_count":null,"outputs":[]}]}